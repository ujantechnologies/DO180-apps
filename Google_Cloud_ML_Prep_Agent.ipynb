{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfOSmbhVLMPBD1GlPtZrsB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujantechnologies/DO180-apps/blob/master/Google_Cloud_ML_Prep_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OrJudgdTuJC",
        "outputId": "6100c51a-a99c-4e5d-9030-f9d2ab955605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 0.3.0 requires websockets<15.0dev,>=13.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -qU 'langgraph==0.2.45' 'langchain-google-genai==2.0.4' 'gradio' 'gradio_agentchatbot'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "RWQfH90gT0Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "\n",
        "class OrderState(TypedDict):\n",
        "    \"\"\"State representing the customer's order conversation.\"\"\"\n",
        "\n",
        "    # The chat conversation. This preserves the conversation history\n",
        "    # between nodes. The `add_messages` annotation indicates to LangGraph\n",
        "    # that state is updated by appending returned messages, not replacing\n",
        "    # them.\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "    # The customer's in-progress order.\n",
        "    order: list[str]\n",
        "\n",
        "    # Flag indicating that the order is placed and completed.\n",
        "    finished: bool\n",
        "\n",
        "\n",
        "# The system instruction defines how the chatbot is expected to behave and includes\n",
        "# rules for when to call different functions, as well as rules for the conversation, such\n",
        "# as tone and what is permitted for discussion.\n",
        "GCPPRACTICEBOT_SYSINT = (\n",
        "    \"system\",  # 'system' indicates the message is a system instruction.\n",
        "    \"You are an Google Cloud Machine Learning Exam Preparation Help Agent.\"\n",
        "    \"You will help the candidate to prepare for the exam by asking multiple choice questions on the below topics.\"\n",
        "    \"Ask questions with a focus on Implementing retrieval augmented generation (RAG) applications by using Vertex AI Agent Builder and Generative AI\"\n",
        "    \"Start with asking what topics the candidate would like to practice on and present the same first.\"\n",
        "    \"Once the candidate responds with the answer you will help evaluate the candidates response and provide reasoning as to why the anser is accurate or inaccurate.\"\n",
        "    \"Once the candidate says quit you will evaluate the candates preparation for the exam and provide guidance as to what more the candidate can practice on  \"\n",
        "    \"Provide motivational and encouraging response to the candidate and say goodbye!\",\n",
        ")\n",
        "\n",
        "# This is the message with which the system opens the conversation.\n",
        "WELCOME_MSG = (\"Welcome to the GCP ML Practice Bot. Type `q` to quit. Are you ready to practice?\"\n",
        ")"
      ],
      "metadata": {
        "id": "S2QrIrx1UQ-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Try using different models. The `pro` models perform the best, especially\n",
        "# with tool-calling. The `flash` models are super fast, and are a good choice\n",
        "# if you need to use the higher free-tier quota.\n",
        "# Check out the features and quota differences here: https://ai.google.dev/pricing\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")\n",
        "\n",
        "\n",
        "def chatbot(state: OrderState) -> OrderState:\n",
        "    \"\"\"The chatbot itself. A simple wrapper around the model's own chat interface.\"\"\"\n",
        "    message_history = [GCPPRACTICEBOT_SYSINT] + state[\"messages\"]\n",
        "    return {\"messages\": [llm.invoke(message_history)]}\n",
        "\n",
        "\n",
        "# Set up the initial graph based on our state definition.\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "# Add the chatbot function to the app graph as a node called \"chatbot\".\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Define the chatbot node as the app entrypoint.\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "chat_graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "ypf1z-5oWNRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "Image(chat_graph.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "lu28O6HHWdmo",
        "outputId": "925f3714-6268-4762-b3ab-e4e654fdab93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "user_msg = \"Hello, what can you do?\"\n",
        "state = chat_graph.invoke({\"messages\": [user_msg]})\n",
        "\n",
        "# The state object contains lots of information. Uncomment the pprint lines to see it all.\n",
        "# pprint(state)\n",
        "\n",
        "# Note that the final state now has 2 messages. Our HumanMessage, and an additional AIMessage.\n",
        "for msg in state[\"messages\"]:\n",
        "    print(f\"{type(msg).__name__}: {msg.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spH7ffYzWgh5",
        "outputId": "0359085a-1334-408c-d7e2-42227ac04c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HumanMessage: Hello, what can you do?\n",
            "AIMessage: Hello! I'm here to help you prepare for the Google Cloud Machine Learning exam, focusing on implementing retrieval augmented generation (RAG) applications using Vertex AI Agent Builder and Generative AI.  \n",
            "\n",
            "To best assist you, let's start by identifying the specific areas you'd like to practice.  Which of the following topics are you most interested in reviewing through multiple-choice questions?\n",
            "\n",
            "A.  Understanding RAG and its components (retrievers, LLMs, etc.)\n",
            "B.  Designing a RAG pipeline with Vertex AI Agent Builder\n",
            "C.  Connecting external knowledge bases to Agent Builder\n",
            "D.  Fine-tuning LLMs for improved RAG performance\n",
            "E.  Evaluating and monitoring RAG application performance\n",
            "F.  Security and access control considerations for RAG applications\n",
            "G. All of the above\n",
            "\n",
            "\n",
            "Please select the letter(s) corresponding to the topic(s) you want to focus on.  Let's get started!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_msg = \"Oh great, let's start\"\n",
        "\n",
        "state[\"messages\"].append(user_msg)\n",
        "state = chat_graph.invoke(state)\n",
        "\n",
        "# pprint(state)\n",
        "for msg in state[\"messages\"]:\n",
        "    print(f\"{type(msg).__name__}: {msg.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IdrKe41W1O-",
        "outputId": "a8bddbd5-85bb-47bc-b869-a32799af9860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HumanMessage: Hello, what can you do?\n",
            "AIMessage: Hello! I'm here to help you prepare for the Google Cloud Machine Learning exam, focusing on implementing retrieval augmented generation (RAG) applications using Vertex AI Agent Builder and Generative AI.  \n",
            "\n",
            "To best assist you, let's start by identifying the specific areas you'd like to practice.  Which of the following topics are you most interested in reviewing through multiple-choice questions?\n",
            "\n",
            "A.  Understanding RAG and its components (retrievers, LLMs, etc.)\n",
            "B.  Designing a RAG pipeline with Vertex AI Agent Builder\n",
            "C.  Connecting external knowledge bases to Agent Builder\n",
            "D.  Fine-tuning LLMs for improved RAG performance\n",
            "E.  Evaluating and monitoring RAG application performance\n",
            "F.  Security and access control considerations for RAG applications\n",
            "G. All of the above\n",
            "\n",
            "\n",
            "Please select the letter(s) corresponding to the topic(s) you want to focus on.  Let's get started!\n",
            "\n",
            "HumanMessage: Oh great, let's start\n",
            "AIMessage: Okay, let's begin!  Please choose from the options provided earlier (A through G) to tell me which topics you'd like to focus on.  I'll then start asking multiple-choice questions based on your selection.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages.ai import AIMessage\n",
        "\n",
        "\n",
        "def human_node(state: OrderState) -> OrderState:\n",
        "    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n",
        "    last_msg = state[\"messages\"][-1]\n",
        "    print(\"Model:\", last_msg.content)\n",
        "\n",
        "    user_input = input(\"User: \")\n",
        "\n",
        "    # If it looks like the user is trying to quit, flag the conversation\n",
        "    # as over.\n",
        "    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n",
        "        state[\"finished\"] = True\n",
        "\n",
        "    return state | {\"messages\": [(\"user\", user_input)]}\n",
        "\n",
        "\n",
        "def chatbot_with_welcome_msg(state: OrderState) -> OrderState:\n",
        "    \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n",
        "\n",
        "    if state[\"messages\"]:\n",
        "        # If there are messages, continue the conversation with the Gemini model.\n",
        "        new_output = llm.invoke([GCPPRACTICEBOT_SYSINT] + state[\"messages\"])\n",
        "    else:\n",
        "        # If there are no messages, start with the welcome message.\n",
        "        new_output = AIMessage(content=WELCOME_MSG)\n",
        "\n",
        "    return state | {\"messages\": [new_output]}\n",
        "\n",
        "\n",
        "# Start building a new graph.\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "# Add the chatbot and human nodes to the app graph.\n",
        "graph_builder.add_node(\"chatbot\", chatbot_with_welcome_msg)\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "\n",
        "# Start with the chatbot again.\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "\n",
        "# The chatbot will always go to the human next.\n",
        "graph_builder.add_edge(\"chatbot\", \"human\");"
      ],
      "metadata": {
        "id": "0WsTz4KrW_r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "\n",
        "def maybe_exit_human_node(state: OrderState) -> Literal[\"chatbot\", \"__end__\"]:\n",
        "    \"\"\"Route to the chatbot, unless it looks like the user is exiting.\"\"\"\n",
        "    if state.get(\"finished\", False):\n",
        "               return END\n",
        "    else:\n",
        "        return \"chatbot\"\n",
        "\n",
        "\n",
        "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
        "\n",
        "chat_with_human_graph = graph_builder.compile()\n",
        "\n",
        "Image(chat_with_human_graph.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Pc_goHtyXJzo",
        "outputId": "09ccc1fa-f329-483e-d98b-107bd4d016f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remember that this will loop forever, unless you input `q`, `quit` or one of the\n",
        "# other exit terms defined in `human_node`.\n",
        "# Uncomment this line to execute the graph:\n",
        "state = chat_with_human_graph.invoke({\"messages\": []})\n",
        "\n",
        "# Things to try:\n",
        "#  - Just chat! There's no ordering or menu yet.\n",
        "#  - 'q' to exit.\n",
        "\n",
        "#pprint(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUFJeaFrXPkN",
        "outputId": "774e7a07-fd9e-40e1-f300-3390e967fa5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Welcome to the GCP ML Practice Bot. Type `q` to quit. Are you ready to practice?\n",
            "User: Yes\n",
            "Model: Great!  Let's start with a quick overview of the topics we can cover related to implementing retrieval augmented generation (RAG) applications using Vertex AI Agent Builder and Generative AI.  We can focus on:\n",
            "\n",
            "1. **Vertex AI Agent Builder Fundamentals:** Understanding the core components, workflow, and capabilities of Agent Builder.\n",
            "2. **Knowledge Base Creation and Management:**  Methods for preparing and structuring data for use within RAG applications.\n",
            "3. **Prompt Engineering for RAG:** Crafting effective prompts to guide the agent's interaction with the knowledge base.\n",
            "4. **Agent Configuration and Tuning:**  Optimizing agent behavior and performance.\n",
            "5. **Integration with Generative AI Models:** Connecting Agent Builder to various generative models available on Vertex AI.\n",
            "6. **Deployment and Monitoring:**  Deploying and monitoring the performance of your RAG application.\n",
            "\n",
            "\n",
            "Which of these topics would you like to practice first?  Please select a number from 1 to 6.\n",
            "\n",
            "User: 3\n",
            "Model: Excellent choice! Prompt engineering is crucial for effective RAG applications.\n",
            "\n",
            "Here's your first multiple-choice question on Prompt Engineering for RAG:\n",
            "\n",
            "**Question:**  Which of the following is NOT a best practice for crafting effective prompts in a RAG application using Vertex AI Agent Builder?\n",
            "\n",
            "A)  Keep prompts concise and focused on the specific information needed.\n",
            "B)  Use clear and unambiguous language, avoiding jargon or ambiguity.\n",
            "C)  Include as much context as possible, even if it's not directly relevant.\n",
            "D)  Specify the desired format of the response (e.g., bullet points, summary).\n",
            "\n",
            "\n",
            "Please select A, B, C, or D.\n",
            "\n",
            "User: B\n",
            "Model: Incorrect. The answer is **C**.\n",
            "\n",
            "While providing context is important, including *irrelevant* context can confuse the agent and lead to less accurate or less efficient responses.  Best practices emphasize providing only the necessary context to guide the agent to the correct information within the knowledge base.  Options A, B, and D are all best practices for prompt engineering in RAG applications.  Clear, concise prompts with specified output formats are essential for effective agent performance.\n",
            "\n",
            "User: q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_menu() -> str:\n",
        "    \"\"\"Provide the latest up-to-date topics to study.\"\"\"\n",
        "    # Note that this is just hard-coded text, but you could connect this to a live stock\n",
        "    # database, or you could use Gemini's multi-modal capabilities and take live photos of\n",
        "    # your cafe's chalk menu or the products on the counter and assmble them into an input.\n",
        "    link = \" A Professional Machine Learning Engineer builds, evaluates, productionizes, and optimizes AI solutions by using Google Cloud capabilities and knowledge of conventional ML approaches. The ML Engineer handles large, complex datasets and creates repeatable, reusable code. The ML Engineer designs and operationalizes generative AI solutions based on foundational models. The ML Engineer considers responsible AI practices, and collaborates closely with other job roles to ensure the long-term success of AI-based applications. The ML Engineer has strong programming skills and experience with data plaorms and distributed data processing tools. The ML Engineer is procient in the areas of model architecture, data and ML pipeline creation, generative AI, and metrics interpretation. The ML Engineer is familiar with foundational concepts of MLOps, application development, infrastructure management, data engineering, and data governance. The ML Engineer enables teams across the organization to use AI solutions. By training, retraining, deploying, scheduling, monitoring, and improving models, the ML Engineer designs and creates scalable, performant solutions. *Note: The exam does not directly assess coding skill. If you have a minimum prociency in Python and Cloud SQL, you should be able to interpret any questions with code snippets. This version of the Professional Machine Learning Engineer exam covers tasks related to generative AI, including building AI solutions using Model Garden and Vertex AI Agent Builder, and evaluating generative AI solutions. To learn more about Google Cloud’s generative AI services, go to Google Cloud Skills Boost to see the Introduction to Generative AI Learning Path (all audiences) or the Generative AI for Developers Learning Path (technical audience). If you are a partner, refer to the Gen AI partner courses: Introduction to Generative AI Learning Path, Generative AI for ML Engineers and Generative AI for Developers. For additional learning, refer to product-specic Gen AI learning oerings such as Explore and Evaluate Models using Model Garden, Vertex AI Agent Builder path (partners), Integrate Search in Applications using Vertex AI Agent Builder, and Generative Chat App with Vertex AI Agent Builder and Dialogow. Section 1: Architecting low-code AI solutions (13% of the exam) 1.1 Developing ML models by using BigQuery ML. Considerations include: ● Building the appropriate BigQuery ML model (e.g., linear and binary classication, regression, time-series, matrix factorization, boosted trees, autoencoders) based on the business problem ● Feature engineering or selection by using BigQuery ML ● Generating predictions by using BigQuery ML 1. 2 Building AI solutions by using ML APIs or foundational models. Considerations include: ● Building applications by using ML APIs from Model Garden ● Building applications by using industry-specic APIs (e.g., Document AI API, Retail API) ● Implementing retrieval augmented generation (RAG) applications by using Vertex AI Agent Builder 1.3 Training models by using AutoML. Considerations include: ● Preparing data for AutoML (e.g., feature selection, data labeling, Tabular Workows on AutoML) ● Using available data (e.g., tabular, text, speech, images, videos) to train custom models ● Using AutoML for tabular data ● Creating forecasting models by using AutoML ● Conguring and debugging trained models Section 2: Collaborating within and across teams to manage data and models (~14% of the exam) 2.1 Exploring and preprocessing organization-wide data (e.g., Cloud Storage, BigQuery, Spanner, Cloud SQL, Apache Spark, Apache Hadoop). Considerations include: ● Organizing dierent types of data (e.g., tabular, text, speech, images, videos) for ecient training ● Managing datasets in Vertex AI ● Data preprocessing (e.g., Dataow, TensorFlow Extended [TFX], BigQuery) ● Creating and consolidating features in Vertex AI Feature Store ● Privacy implications of data usage and/or collection (e.g., handling sensitive data such as personally identiable information [PII] and protected health information [PHI]) ● Ingesting dierent data sources (e.g., text documents) into Vertex AI for inference 2.2 Model prototyping using Jupyter notebooks. Considerations include: ● Choosing the appropriate Jupyter backend on Google Cloud (e.g., Vertex AI Workbench, Colab Enterprise, notebooks on Dataproc) ● Applying security best practices in Vertex AI Workbench ● Using Spark kernels ● Integrating code source repositories ● Developing models in Vertex AI Workbench by using common frameworks (e.g., TensorFlow, PyTorch, sklearn, Spark, JAX) ● Leveraging a variety of foundational and open-source models in Model Garden 2.3 Tracking and running ML experiments. Considerations include: ● Choosing the appropriate Google Cloud environment for development and experimentation (e.g., Vertex AI Experiments, Kubeow Pipelines, Vertex AI TensorBoard with TensorFlow and PyTorch) given the framework ● Evaluating generative AI solutions Section 3: Scaling prototypes into ML models (~18% of the exam) 3.1 Building models. Considerations include: ● Choosing ML framework and model architecture ● Modeling techniques given interpretability requirements 3.2 Training models. Considerations include: ● Organizing training data (e.g., tabular, text, speech, images, videos) on Google Cloud (e.g., Cloud Storage, BigQuery) ● Ingestion of various le types (e.g., CSV, JSON, images, Hadoop, databases) into training ● Training using dierent SDKs (e.g., Vertex AI custom training, Kubeow on Google Kubernetes Engine, AutoML, tabular workows) ● Using distributed training to organize reliable pipelines ● Hyperparameter tuning ● Troubleshooting ML model training failures ● Fine-tuning foundational models (e.g., Vertex AI, Model Garden) 3.3 Choosing appropriate hardware for training. Considerations include: ● Evaluation of compute and accelerator options (e.g., CPU, GPU, TPU, edge devices) ● Distributed training with TPUs and GPUs (e.g., Reduction Server on Vertex AI, Horovod) Section 4: Serving and scaling models (~20% of the exam) 4.1 Serving models. Considerations include: ● Batch and online inference (e.g., Vertex AI, Dataow, BigQuery ML, Dataproc) ● Using dierent frameworks (e.g., PyTorch, XGBoost) to serve models ● Organizing a model registry ● A/B testing dierent versions of a model 4.2 Scaling online model serving. Considerations include: ● Vertex AI Feature Store ● Vertex AI public and private endpoints ● Choosing appropriate hardware (e.g., CPU, GPU, TPU, edge) ● Scaling the serving backend based on the throughput (e.g., Vertex AI Prediction, containerized serving) ● Tuning ML models for training and serving in production (e.g., simplication techniques, optimizing the ML solution for increased performance, latency, memory, throughput) Section 5: Automating and orchestrating ML pipelines (~22% of the exam) 5.1 Developing end-to-end ML pipelines. Considerations include: ● Data and model validation ● Ensuring consistent data pre-processing between training and serving ● Hosting third-party pipelines on Google Cloud (e.g., MLFlow) ● Identifying components, parameters, triggers, and compute needs (e.g., Cloud Build, Cloud Run) ● Orchestration framework (e.g., Kubeow Pipelines, Vertex AI Pipelines, Cloud Composer) ● Hybrid or multicloud strategies ● System design with TFX components or Kubeow DSL (e.g., Dataow) 5.2 Automating model retraining. Considerations include: ● Determining an appropriate retraining policy ● Continuous integration and continuous delivery (CI/CD) model deployment (e.g., Cloud Build, Jenkins) 5.3 Tracking and auditing metadata. Considerations include: ● Tracking and comparing model artifacts and versions (e.g., Vertex AI Experiments, Vertex ML Metadata) ● Hooking into model and dataset versioning ● Model and data lineage Section 6: Monitoring AI solutions (~13% of the exam) 6.1 Identifying risks to AI solutions. Considerations include: ● Building secure AI systems by protecting against unintentional exploitation of data or models (e.g., hacking) ● Aligning with Google’s Responsible AI practices (e.g., monitoring for bias) ● Assessing AI solution readiness (e.g., fairness, bias) ● Model explainability on Vertex AI (e.g., Vertex AI Prediction) 6.2 Monitoring, testing, and troubleshooting AI solutions. Considerations include: ● Establishing continuous evaluation metrics (e.g., Vertex AI Model Monitoring, Explainable AI) ● Monitoring for training-serving skew ● Monitoring for feature aribution dri ● Monitoring model performance against baselines, simpler models, and across the time dimension ● Monitoring for common training and serving errors \"\n",
        "    message = \"Provide a list of  Options to Practice from :\"+ link\n",
        "    new_output = llm.invoke([ (\"user\",message)])\n",
        "   # print(new_output)\n",
        "    return new_output"
      ],
      "metadata": {
        "id": "KvSaJSkYdQV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "# Define the tools and create a \"tools\" node.\n",
        "tools = [get_menu]\n",
        "tool_node = ToolNode(tools)\n",
        "\n",
        "# Attach the tools to the model so that it knows what it can call.\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def maybe_route_to_tools(state: OrderState) -> Literal[\"tools\", \"human\"]:\n",
        "    \"\"\"Route between human or tool nodes, depending if a tool call is made.\"\"\"\n",
        "    if not (msgs := state.get(\"messages\", [])):\n",
        "        raise ValueError(f\"No messages found when parsing state: {state}\")\n",
        "\n",
        "    # Only route based on the last message.\n",
        "    msg = msgs[-1]\n",
        "\n",
        "    # When the chatbot returns tool_calls, route to the \"tools\" node.\n",
        "    if hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n",
        "        return \"tools\"\n",
        "    else:\n",
        "        return \"human\"\n",
        "\n",
        "\n",
        "def chatbot_with_tools(state: OrderState) -> OrderState:\n",
        "    \"\"\"The chatbot with tools. A simple wrapper around the model's own chat interface.\"\"\"\n",
        "    defaults = {\"order\": [], \"finished\": False}\n",
        "\n",
        "    if state[\"messages\"]:\n",
        "        new_output = llm_with_tools.invoke([GCPPRACTICEBOT_SYSINT ] + state[\"messages\"])\n",
        "    else:\n",
        "        new_output = AIMessage(content=WELCOME_MSG)\n",
        "\n",
        "    # Set up some defaults if not already set, then pass through the provided state,\n",
        "    # overriding only the \"messages\" field.\n",
        "    return defaults | state | {\"messages\": [new_output]}\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(OrderState)\n",
        "\n",
        "# Add the nodes, including the new tool_node.\n",
        "graph_builder.add_node(\"chatbot\", chatbot_with_tools)\n",
        "graph_builder.add_node(\"human\", human_node)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Chatbot may go to tools, or human.\n",
        "graph_builder.add_conditional_edges(\"chatbot\", maybe_route_to_tools)\n",
        "# Human may go back to chatbot, or exit.\n",
        "graph_builder.add_conditional_edges(\"human\", maybe_exit_human_node)\n",
        "\n",
        "# Tools always route back to chat afterwards.\n",
        "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
        "\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_with_menu = graph_builder.compile()\n",
        "\n",
        "Image(graph_with_menu.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "zTWazLsoeP67",
        "outputId": "0c88c602-173b-44d4-cf3d-7a53f9c2b909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h_wr9WX4i_zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " state = graph_with_menu.invoke({\"messages\": []})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqgYk0z_fUFA",
        "outputId": "68c609be-8d1f-4137-886f-1d73f8cddeef"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Welcome to the GCP ML Practice Bot. Type `q` to quit. Are you ready to practice?\n",
            "User: Y\n",
            "Model: Great! What topics would you like to practice today?  I can help you with questions on Implementing retrieval augmented generation (RAG) applications by using Vertex AI Agent Builder and Generative AI.\n",
            "\n",
            "User: 3\n",
            "Model: Please specify the topics you would like to practice.  I'm ready when you are!\n",
            "\n",
            "User: Yes\n",
            "Model: Okay, let's begin!  Here's your first question:\n",
            "\n",
            "**Question 1:** Which of the following is NOT a key component of a Retrieval Augmented Generation (RAG) application built using Vertex AI?\n",
            "\n",
            "A)  A vector database to store embeddings of documents.\n",
            "B)  A large language model (LLM) to generate text.\n",
            "C)  A separate model to perform sentiment analysis on user queries.\n",
            "D)  A retriever to fetch relevant documents based on user queries.\n",
            "\n",
            "\n",
            "Please choose A, B, C, or D.\n",
            "\n",
            "User: C\n",
            "Model: Correct! The answer is C.\n",
            "\n",
            "A RAG application uses an LLM to generate text based on retrieved information, a retriever to find relevant documents, and a vector database to store and search those documents efficiently.  Sentiment analysis is not a core component of a basic RAG pipeline, although it could be added as an extra feature.  Therefore, C is the component that is NOT a key component of a basic RAG application built using Vertex AI.\n",
            "  \n",
            "\n",
            "Let's move on to the next question.\n",
            "\n",
            "**Question 2:**  In a Vertex AI Agent Builder RAG application, what is the primary role of the retriever?\n",
            "\n",
            "A) To generate human-like text responses.\n",
            "B) To store and manage the knowledge base documents.\n",
            "C) To select the most relevant documents from the knowledge base based on the user's query.\n",
            "D) To embed documents into vector space.\n",
            "\n",
            "\n",
            "Please choose A, B, C, or D.\n",
            "\n",
            "User: B\n",
            "Model: Incorrect. The correct answer is C.\n",
            "\n",
            "While the retriever interacts with the knowledge base (which is often stored in a vector database), its primary role is to *select* the most relevant documents from that knowledge base, based on the user's query.  Storing and managing documents is handled by the vector database itself.  Generating text is the role of the LLM.  Embedding documents into vector space is usually a preprocessing step.\n",
            "Let's try another question.\n",
            "\n",
            "\n",
            "**Question 3:** Which of the following is a benefit of using a vector database in a RAG application?\n",
            "\n",
            "A) It simplifies the process of creating prompts for the LLM.\n",
            "B) It allows for efficient similarity search of documents based on their semantic meaning.\n",
            "C) It automatically performs sentiment analysis on the retrieved documents.\n",
            "D) It directly generates human-readable summaries of the retrieved documents.\n",
            "\n",
            "\n",
            "Please choose A, B, C, or D.\n",
            "\n",
            "\n",
            "User: q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    state = graph_with_menu.invoke({\"messages\": []})\n",
        "    return state\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "lzcVIetPysih",
        "outputId": "15511656-13fe-403d-fdc8-27eda662f083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c47b141e81d1550274.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c47b141e81d1550274.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from gradio_agentchatbot import AgentChatbot, stream_from_transformers_agent, ChatMessage\n",
        "from langchain.agents import load_tools\n",
        "\n",
        "agent = ReactCodeAgent(tools=[image_generation_tool, search_tool], llm_engine=llm_engine)\n",
        "\n",
        "\n",
        "def interact_with_agent(prompt, messages):\n",
        "    messages.append(ChatMessage(role=\"user\", content=prompt))\n",
        "    yield messages\n",
        "    for msg in stream_from_transformers_agent(agent, prompt):\n",
        "        messages.append(msg)\n",
        "        yield messages\n",
        "    yield messages\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = AgentChatbot(label=\"Agent\")\n",
        "    text_input = gr.Textbox(lines=1, label=\"Chat Message\")\n",
        "    text_input.submit(interact_with_agent, [text_input, chatbot], [chatbot])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "M0rAjHio1Ug-",
        "outputId": "3fe477f1-a5e5-4327-8f21-f4b66b0af905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.agents.agents because of the following error (look up to see its traceback):\nFailed to import transformers.models.auto.processing_auto because of the following error (look up to see its traceback):\n'NoneType' object has no attribute 'Rlocation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/processing_auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureExtractionMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mimage_processing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageProcessingMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/image_processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_processing_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageProcessingMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcenter_crop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpsSet\u001b[0m \u001b[0;31m# line: 170\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauthoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelAnalyzer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAnalyzer\u001b[0m \u001b[0;31m# line: 35\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthoring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthoring\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatible\u001b[0m \u001b[0;31m# line: 265\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/authoring/authoring.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m   _deprecated_conversion_binary = _resource_loader.get_path_to_datafile(\n\u001b[0m\u001b[1;32m    152\u001b[0m       \u001b[0;34m\"../toco/python/toco_from_protos\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/resource_loader.py\u001b[0m in \u001b[0;36mget_path_to_datafile\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     new_fpath = r.Rlocation(\n\u001b[0m\u001b[1;32m    119\u001b[0m         _os.path.abspath(_os.path.join('tensorflow', path)))\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Rlocation'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/agents/agents.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0magent_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentAudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAgentImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdefault_tools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBASE_PYTHON_TOOLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFinalAnswerTool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup_default_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mllm_engine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHfApiEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessageRole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/agents/default_tools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpython_interpreter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLIST_SAFE_MODULES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_python_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTOOL_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOOL_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/agents/tools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m from ..utils import (\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1794\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1796\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.auto.processing_auto because of the following error (look up to see its traceback):\n'NoneType' object has no attribute 'Rlocation'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-b58dd0401016>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio_agentchatbot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentChatbot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_from_transformers_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReactCodeAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_generation_tool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_tool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_engine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio_agentchatbot/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0magentchatbot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentChatbot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatbotData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from .utils import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mstream_from_transformers_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mChatMessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mThoughtMetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio_agentchatbot/agentchatbot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmove_resource_to_block_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatbotData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChatFileMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio_agentchatbot/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgradio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_classes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradioModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFileData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradioRootModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthreading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1793\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1796\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.agents.agents because of the following error (look up to see its traceback):\nFailed to import transformers.models.auto.processing_auto because of the following error (look up to see its traceback):\n'NoneType' object has no attribute 'Rlocation'"
          ]
        }
      ]
    }
  ]
}